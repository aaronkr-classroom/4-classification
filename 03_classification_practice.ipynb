{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3JcRDiRYIoz"
      },
      "source": [
        "**3장 – 분류**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP9f58e9YIo2"
      },
      "source": [
        "_이 노트북은 3장의 모든 샘플 코드와 연습 문제 정답을 담고 있습니다._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wifVmy8IYIo2"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/rickiepark/handson-ml3/blob/main/03_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofy3ew3HYIo2"
      },
      "source": [
        "# 3.0 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SChsGt-DYIo3"
      },
      "source": [
        "파이썬 3.7 또는 그 이상이 필요합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n8giqpEsYIo3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "assert sys.version_info >= (3, 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSrGuGtAYIo4"
      },
      "source": [
        "Scikit-Learn ≥1.0.1이 필요합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DjCtPi1NYIo4"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import sklearn\n",
        "\n",
        "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLUteiNzYIo4"
      },
      "source": [
        "이전 장과 마찬가지로 그래프를 보기 좋게 그리기 위해 기본 폰트 크기를 설정합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v6ixGzRuYIo5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iFTC1RcYIo5"
      },
      "source": [
        "`images/classification` 폴더가 없다면 이 폴더를 만들고 고해상도 이미지 저장을 위해 노트북에서 사용할 `save_fig()` 함수를 정의합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "P08ieQMCYIo5"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "IMAGES_PATH = Path() / \"images\"\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDfpS4pYYIpX"
      },
      "source": [
        "# 연습문제 해답"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs_ecREgYIpX"
      },
      "source": [
        "## 1. 97% 정확도의 MNIST 분류기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoxkKJwuYIpX",
        "tags": []
      },
      "source": [
        "문제: _MNIST 데이터셋으로 분류기를 만들어 테스트 세트에서 97% 정확도를 달성해보세요. 힌트: `KNeighborsClassifier`가 이 작업에 아주 잘 맞습니다. 좋은 하이퍼파라미터 값만 찾으면 됩니다(`weights`와 `n_neighbors` 하이퍼파라미터로 그리드 탐색을 시도해보세요)._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-lUNw-EYIpY"
      },
      "source": [
        "K-최근접 이웃 분류기를 사용해 테스트 세트에서 성능을 측정해 보죠. 이 모델을 기준 모델로 삼습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVvnBLkzYIpY",
        "outputId": "456e0cdf-138b-496a-c3e9-32d179521ef3"
      },
      "outputs": [],
      "source": [
        "knn_clf = KNeighborsClassifier()\n",
        "knn_clf.fit(X_train, y_train)\n",
        "baseline_accuracy = knn_clf.score(X_test, y_test)\n",
        "baseline_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwy0WXzwYIpY"
      },
      "source": [
        "훌륭합니다! 기본 하이퍼파라미터를 사용하는 KNN 분류기는 우리 목표에 이미 매우 근접합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbzlTotwYIpY"
      },
      "source": [
        "하이퍼파라미터를 튜닝하면 도움이 될 수 있는지 살펴봅시다. 탐색 속도를 높이기 위해 처음 10,000개의 이미지에 대해서만 훈련해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "y0Y3AIvbYIpY",
        "outputId": "16ee94c0-e094-4288-977d-5ede099e995a"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [{'weights': [\"uniform\", \"distance\"], 'n_neighbors': [3, 4, 5, 6]}]\n",
        "\n",
        "knn_clf = KNeighborsClassifier()\n",
        "grid_search = GridSearchCV(knn_clf, param_grid, cv=5)\n",
        "grid_search.fit(X_train[:10_000], y_train[:10_000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb7yvMB_YIpZ",
        "outputId": "9914261d-56ae-49dc-fca0-33b7ae77cb94"
      },
      "outputs": [],
      "source": [
        "grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAq1d7pdYIpZ",
        "outputId": "517c2cde-b1fc-4943-8d95-fd325d478a2b"
      },
      "outputs": [],
      "source": [
        "grid_search.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVbLefG3YIpZ"
      },
      "source": [
        "점수가 떨어졌지만 10,000개의 이미지로만 훈련했기 때문에 예상했던 결과입니다. 이제 최상의 모델을 가져와 전체 훈련 세트에서 다시 훈련해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwflgK-4YIpZ",
        "outputId": "bc9f47e5-0f85-4121-a536-fa88852fae08"
      },
      "outputs": [],
      "source": [
        "grid_search.best_estimator_.fit(X_train, y_train)\n",
        "tuned_accuracy = grid_search.score(X_test, y_test)\n",
        "tuned_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKyZPLMuYIpZ"
      },
      "source": [
        "97% 정확도 목표에 도달했습니다! 🥳"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRz1CmZoYIpa"
      },
      "source": [
        "## 2. 데이터 증식"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajxP562cYIpa"
      },
      "source": [
        "문제: _MNIST 이미지를 (왼, 오른, 위, 아래) 어느 방향으로든 한 픽셀 이동시킬 수 있는 함수를 만들어보세요. `scipy.ndimage.interpolation` 모듈의 `shift()` 함수를 사용할 수 있습니다. 예를 들어 `shift(image, [2, 1], cval=0)`은 아래로 2픽셀, 오른쪽으로 1픽셀 이동시킵니다. 그런 다음 훈련 세트에 있는 각 이미지에 대해 네 개의 이동된 복사본(방향마다 한 개씩)을 만들어 훈련 세트에 추가하세요. 마지막으로 이 확장된 데이터셋에서 앞에서 찾은 최선의 모델을 훈련시키고 테스트 세트에서 정확도를 측정해보세요. 모델 성능이 더 높아졌는지 확인해보세요! 인위적으로 훈련 세트를 늘리는 이 기법을 _데이터 증식_ 또는 _훈련 세트 확장_(training set expansion)이라고 합니다._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYQNIEcdYIpa"
      },
      "source": [
        "각 이미지의 약간 변형된 버전을 추가하여 MNIST 데이터셋을 증식해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "JElcXk4NYIpa"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "24dTQ0beYIpa"
      },
      "outputs": [],
      "source": [
        "def shift_image(image, dx, dy):\n",
        "    image = image.reshape((28, 28))\n",
        "    shifted_image = shift(image, [dy, dx], cval=0, mode=\"constant\")\n",
        "    return shifted_image.reshape([-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDI-PP7VYIpa"
      },
      "source": [
        "작동하는지 확인해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "lKHvxTx3YIpa",
        "outputId": "95849eb9-d8ba-48b2-b2af-5a0abb52bdab"
      },
      "outputs": [],
      "source": [
        "image = X_train[1000]  # 데모에 사용할 임의의 숫자\n",
        "shifted_image_down = shift_image(image, 0, 5)\n",
        "shifted_image_left = shift_image(image, -5, 0)\n",
        "\n",
        "plt.figure(figsize=(12, 3))\n",
        "plt.subplot(131)\n",
        "plt.title(\"Original\")\n",
        "plt.imshow(image.reshape(28, 28),\n",
        "           interpolation=\"nearest\", cmap=\"Greys\")\n",
        "plt.subplot(132)\n",
        "plt.title(\"Shifted down\")\n",
        "plt.imshow(shifted_image_down.reshape(28, 28),\n",
        "           interpolation=\"nearest\", cmap=\"Greys\")\n",
        "plt.subplot(133)\n",
        "plt.title(\"Shifted left\")\n",
        "plt.imshow(shifted_image_left.reshape(28, 28),\n",
        "           interpolation=\"nearest\", cmap=\"Greys\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GisfW9vYIpb"
      },
      "source": [
        "좋아 보이네요! 이제 모든 이미지를 왼쪽, 오른쪽, 위, 아래로 1픽셀씩 이동하여 증식된 훈련 세트를 만들어 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "SO-7KRxeYIpb"
      },
      "outputs": [],
      "source": [
        "X_train_augmented = [image for image in X_train]\n",
        "y_train_augmented = [label for label in y_train]\n",
        "\n",
        "for dx, dy in ((-1, 0), (1, 0), (0, 1), (0, -1)):\n",
        "    for image, label in zip(X_train, y_train):\n",
        "        X_train_augmented.append(shift_image(image, dx, dy))\n",
        "        y_train_augmented.append(label)\n",
        "\n",
        "X_train_augmented = np.array(X_train_augmented)\n",
        "y_train_augmented = np.array(y_train_augmented)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6g-VYPLYIpb"
      },
      "source": [
        "증식된 훈련 세트를 섞어 보겠습니다. 그렇지 않으면 이동된 모든 이미지가 함께 묶입니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "xjNDXmrrYIpd"
      },
      "outputs": [],
      "source": [
        "shuffle_idx = np.random.permutation(len(X_train_augmented))\n",
        "X_train_augmented = X_train_augmented[shuffle_idx]\n",
        "y_train_augmented = y_train_augmented[shuffle_idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPN0K0IQYIpd"
      },
      "source": [
        "이제 이전 연습문제에서 찾은 최상의 하이퍼파라미터를 사용하여 모델을 훈련해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "tYekWVivYIpd"
      },
      "outputs": [],
      "source": [
        "knn_clf = KNeighborsClassifier(**grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "qUU8cRb8YIpd",
        "outputId": "16a64c02-c91f-495e-c84e-0902058f13ee"
      },
      "outputs": [],
      "source": [
        "knn_clf.fit(X_train_augmented, y_train_augmented)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmCANydfYIpd"
      },
      "source": [
        "**경고**: 다음 셀을 실행하는 데 몇 분 정도 걸릴 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi6ON_wBYIpd",
        "outputId": "d4b70b11-fa70-4e9e-becb-6b78040dac0a"
      },
      "outputs": [],
      "source": [
        "augmented_accuracy = knn_clf.score(X_test, y_test)\n",
        "augmented_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQKRxf51YIpe"
      },
      "source": [
        "단순히 데이터를 보강하는 것만으로도 정확도가 0.5% 향상되었습니다. 그다지 인상적으로 들리지 않을 수도 있지만 실제로는 오류율이 크게 감소했음을 의미합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acQy5bzWYIpe",
        "outputId": "cc35a625-cb5a-458c-90d3-88fea98e1605",
        "tags": []
      },
      "outputs": [],
      "source": [
        "error_rate_change = (1 - augmented_accuracy) / (1 - tuned_accuracy) - 1\n",
        "print(f\"error_rate_change = {error_rate_change:.0%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLA2rpq-YIpe"
      },
      "source": [
        "데이터 증식 덕분에 오류율이 상당히 감소했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ouh8YflYIpf"
      },
      "source": [
        "## 3. 타이타닉 데이터셋 도전하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9GrVmvKYIpf"
      },
      "source": [
        "문제: _타이타닉(Titanic) 데이터셋에 도전해보세요. [캐글](https://www.kaggle.com/c/titanic)이 시작하기 좋습니다. 또는 https://homl.info/titanic.tgz 에서 데이터를 다운로드하고, 2장의 주택 데이터에서 했던 것처럼 이 파일의 압축을 풀 수 있습니다. 이렇게 하면 CSV 파일 train.csv와 test.csv가 두 개가 생성되며, 이 파일을 `pandas.read_csv()`를 사용해 로드할 수 있습니다. 다른 열을 기반으로 `Survived` 열을 예측할 수 있는 분류기를 훈련하는 것이 목표입니다._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8cx9EHnYIpf"
      },
      "source": [
        "데이터를 가져와서 로드해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "3HFEamKyYIpf"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "def load_titanic_data():\n",
        "    tarball_path = Path(\"datasets/titanic.tgz\")\n",
        "    if not tarball_path.is_file():\n",
        "        Path(\"datasets\").mkdir(parents=True, exist_ok=True)\n",
        "        url = \"https://github.com/ageron/data/raw/main/titanic.tgz\"\n",
        "        urllib.request.urlretrieve(url, tarball_path)\n",
        "        with tarfile.open(tarball_path) as titanic_tarball:\n",
        "            titanic_tarball.extractall(path=\"datasets\")\n",
        "    return [pd.read_csv(Path(\"datasets/titanic\") / filename)\n",
        "            for filename in (\"train.csv\", \"test.csv\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "x9okileRYIpf"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = load_titanic_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyYzUnHkYIpf"
      },
      "source": [
        "이 데이터는 이미 훈련 세트와 테스트 세트로 분할되어 있습니다. 하지만 테스트 데이터에는 레이블이 포함되어 있지 않습니다. 목표는 훈련 데이터에서 최상의 모델을 훈련한 다음, 테스트 데이터에서 예측을 만들고 캐글에 업로드하여 최종 점수를 확인하는 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmJm3gLxYIpg"
      },
      "source": [
        "훈련 세트의 상위 몇 줄을 살펴봅시다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Rydcusx0YIpg",
        "outputId": "f0be0ad7-aad8-4ba6-8d41-e775bfd7f81a"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN9ofFloYIpg"
      },
      "source": [
        "특성은 다음과 같은 의미를 갖습니다:\n",
        "* **PassengerId**: 각 승객의 고유 식별자\n",
        "* **Survived**: 타깃입니다. 0은 승객이 생존하지 못했음을 의미하고, 1은 생존했음을 의미합니다.\n",
        "* **Pclass**: 객실 등급.\n",
        "* **Name**, **Sex**, **Age**: 설명이 필요 없는 특성\n",
        "* **SibSp**: 타이타닉 호에 탑승한 승객의 형제자매 및 배우자 수.\n",
        "* **Parch**: 타이타닉에 탑승한 승객의 자녀 및 부모 수.\n",
        "* **Ticket**: 티켓 ID\n",
        "* **Fare**: 지불한 가격(파운드)\n",
        "* **Cabin**: 승객의 객실 번호\n",
        "* **Embarked**: 승객이 타이타닉 호에 승선한 장소"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0jTWjsCYIpg"
      },
      "source": [
        "승객의 나이, 성별, 객실 등급, 탑승 장소 등의 특성을 기반으로 승객의 생존 여부를 예측하는 것이 목표입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe0Mdk7MYIpg"
      },
      "source": [
        "명시적으로 `PassengerId` 열을 인덱스 열로 설정해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "7N-lyG97YIph"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.set_index(\"PassengerId\")\n",
        "test_data = test_data.set_index(\"PassengerId\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RNALh0wYIph"
      },
      "source": [
        "누락된 데이터의 양을 확인하기 위해 자세한 정보를 확인해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fKyMZYmYIph",
        "outputId": "76f7b6ed-07c3-4825-c9c5-595bd96bdb02"
      },
      "outputs": [],
      "source": [
        "train_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUwhCrY8YIph",
        "outputId": "7fe87fb6-eb5a-46f6-ee75-4d04df269909"
      },
      "outputs": [],
      "source": [
        "train_data[train_data[\"Sex\"]==\"female\"][\"Age\"].median()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTjk85u6YIph"
      },
      "source": [
        "**Age**, **Cabin** 및 **Embarked** 특성은 (891개 non-null이 아니기 때문에) 때때로 null입니다. 특히 **Cabin**(77%가 null)이 그렇습니다. 지금은 **Cabin**은 무시하고 나머지에 집중하겠습니다. **Age** 특성에는 약 19%의 null 값이 있으므로 이를 어떻게 처리할지 결정해야 합니다. null 값을 평균 연령으로 대체하는 것이 합리적입니다. 다른 열을 기반으로 나이를 예측하면 좀 더 스마트할 수 있지만(예를 들어, 1등급 객실의 나이 중앙값은 37세, 2등급은 29세, 3등급은 24세), 여기서는 간단하게 전체 중앙값을 사용하기로 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTLEFbWfYIpi"
      },
      "source": [
        "**Name** 및 **Ticket** 특성은 어느 정도 가치가 있을 수 있지만 모델이 사용할 수 있는 유용한 숫자로 변환하기에는 약간 까다롭습니다. 따라서 지금은 무시하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaPWIi4KYIpi"
      },
      "source": [
        "숫자 특성을 살펴보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Ur17E_3zYIpi",
        "outputId": "b43029ff-4b3f-4529-97ca-8b601a150720"
      },
      "outputs": [],
      "source": [
        "train_data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBNnvikGYIpi"
      },
      "source": [
        "* 이런, **Survived**가 38%뿐입니다! 😭 40%에 충분히 근접한 수치이므로 정확도는 모델을 평가하는 합리적인 지표가 될 것입니다.\n",
        "* 평균 **Fare**는 32.20파운드로 그렇게 비싸지 않은 것 같습니다(하지만 그 당시에는 많은 돈이었을 것입니다).\n",
        "* 평균 **Age**는 30세 미만이었습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZm6s_hsYIpi"
      },
      "source": [
        "타깃이 실제로 0 또는 1인지 확인해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiUavk0sYIpj",
        "outputId": "b9e4f9c2-e7e2-4de0-8b7c-18c93a8dc420"
      },
      "outputs": [],
      "source": [
        "train_data[\"Survived\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dfePbFnYIpj"
      },
      "source": [
        "이제 모든 범주형 특성에 대해 간단히 살펴보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQMgm_EQYIpj",
        "outputId": "18916bab-ea42-425b-a7ab-83d8969b9ca4"
      },
      "outputs": [],
      "source": [
        "train_data[\"Pclass\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHk4MhFaYIpj",
        "outputId": "ec6bd818-90c1-4033-b024-2c0813fff5a8"
      },
      "outputs": [],
      "source": [
        "train_data[\"Sex\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD8WOis_YIpj",
        "outputId": "da4163d0-3c2b-4728-d75e-58512fad0447"
      },
      "outputs": [],
      "source": [
        "train_data[\"Embarked\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEpPDeeUYIpl"
      },
      "source": [
        "승선 위치 특성은 승객이 승선한 위치를 알려줍니다: C=Cherbourg, Q=Queenstown, S=Southampton."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mftLow6fYIpm"
      },
      "source": [
        "이제 숫자 특성에 대한 파이프라인부터 시작하여 전처리 파이프라인을 구축해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "w1Xk8Ao4YIpm"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler())\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJjDOe50YIpm"
      },
      "source": [
        "이제 범주형 특성에 대한 파이프라인을 구축할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "7FydJqFgYIpm"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "zBNdTTYeYIpm"
      },
      "outputs": [],
      "source": [
        "# 사이킷런 1.2버전에서 OneHotEncoder의 `sparse_output` 매개변수가 추가되었고\n",
        "# `sparse` 매개변수는 1.4버전에서 삭제되었습니다.\n",
        "cat_pipeline = Pipeline([\n",
        "        (\"ordinal_encoder\", OrdinalEncoder()),\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"cat_encoder\", OneHotEncoder(sparse_output=False)),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8gVZkyMYIpm"
      },
      "source": [
        "마지막으로 숫자 파이프라인과 범주 파이프라인을 결합해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "n1DRHh_PYIpn"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "num_attribs = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
        "cat_attribs = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
        "\n",
        "preprocess_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_attribs),\n",
        "        (\"cat\", cat_pipeline, cat_attribs),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cslEzWznYIpn"
      },
      "source": [
        "멋지네요! 이제 원시 데이터를 가져와 원하는 머신 러닝 모델에 공급 가능한 수치 입력 특성을 출력하는 멋진 전처리 파이프라인이 생겼습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPysEffYYIpn",
        "outputId": "7349e39a-5594-466c-d8fd-9be48a5eeed5"
      },
      "outputs": [],
      "source": [
        "X_train = preprocess_pipeline.fit_transform(train_data)\n",
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvcq3vFnYIpn"
      },
      "source": [
        "레이블을 챙기는 것도 잊지 마세요:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "IGjerhBgYIpn"
      },
      "outputs": [],
      "source": [
        "y_train = train_data[\"Survived\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVLUs5F9YIpn"
      },
      "source": [
        "이제 분류기를 훈련할 준비가 되었습니다. 먼저 `RandomForestClassifier`로 시작해 보죠:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "TNVzv2t-YIpo",
        "outputId": "660b748b-4c40-4430-e441-7f105942677f"
      },
      "outputs": [],
      "source": [
        "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "forest_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExZGFo-hYIpo"
      },
      "source": [
        "모델이 학습되었으니 이제 이 모델을 사용하여 테스트 세트에 대한 예측을 수행해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "l4fFQthQYIpp"
      },
      "outputs": [],
      "source": [
        "X_test = preprocess_pipeline.transform(test_data)\n",
        "y_pred = forest_clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeUpcKuaYIpp"
      },
      "source": [
        "이제 이러한 예측이 포함된 CSV 파일을 (캐글이 기대하는 형식에 맞추어) 작성한 다음 업로드하고 최선이기를 바랄 수 있습니다. 하지만 잠깐만요! 그냥 희망하는 것보다 더 좋은 방법이 있습니다. 교차 검증을 사용하여 모델이 얼마나 좋은지 알아보는 것은 어떨까요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-G1_ymmYIpp",
        "outputId": "7f3dfb1e-1fa2-4c09-d43c-343f39e5cfa6"
      },
      "outputs": [],
      "source": [
        "forest_scores = cross_val_score(forest_clf, X_train, y_train, cv=10)\n",
        "forest_scores.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96-vDdREYIpp"
      },
      "source": [
        "좋아요, 나쁘지 않네요! 캐글에서 타이타닉 대회의 [리더보드](https://www.kaggle.com/c/titanic/leaderboard)를 보면, 이 점수가 상위 2%에 속하는 것을 확인할 수 있습니다, 우후! 100% 정확도를 달성한 캐글러도 있었지만, 타이타닉의 [희생자 명단](https://www.encyclopedia-titanica.org/titanic-victims/)을 쉽게 찾아볼 수 있는 것으로 보아 머신러닝의 영향이 거의 없었던 것 같습니다! 😆"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS3EKtoSYIpp"
      },
      "source": [
        "`SVC`를 시도해 보죠:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br-RK5mSYIpq",
        "outputId": "a7a46a90-0ca3-49f9-b477-aed35684e65d"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_clf = SVC(gamma=\"auto\")\n",
        "svm_scores = cross_val_score(svm_clf, X_train, y_train, cv=10)\n",
        "svm_scores.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPxadT55YIpq"
      },
      "source": [
        "좋아요! 이 모델이 더 좋아 보입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKRlewnPYIpq"
      },
      "source": [
        "하지만 10개의 교차 검증 폴드에 대한 평균 정확도만 보는 대신 각 모델에 대한 10개의 모든 점수를 하위 및 상위 사분위수를 강조하는 박스 플롯과 점수의 범위를 보여주는 '수염'을 함께 그려 보겠습니다(이 시각화를 제안해 준 Nevin Yilmaz에게 감사드립니다). `boxplot()` 함수는 이상치을 감지하며 수염에는 포함하지 않는다는 점에 유의하세요. 구체적으로, 하위 사분위수가 $Q_1$이고 상위 사분위수가 $Q_3$인 경우 사분위수 간 범위가 $IQR = Q_3 - Q_1$(상자의 높이)이며, $Q_1 - 1.5 \\times IQR$보다 낮은 점수는 이상치이고, $Q3 + 1.5 \\times IQR$보다 큰 점수도 이상치에 해당합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "lDVrqvvBYIpq",
        "outputId": "f5381b17-e6de-4916-b9ba-206bcaf9b7b1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot([1]*10, svm_scores, \".\")\n",
        "plt.plot([2]*10, forest_scores, \".\")\n",
        "plt.boxplot([svm_scores, forest_scores], labels=(\"SVM\", \"Random Forest\"))\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isO4LLCRYIpq"
      },
      "source": [
        "랜덤 포레스트 분류기는 10개 폴드 중 하나에서 매우 높은 점수를 받았지만 전반적으로 평균 점수가 낮고 더 널리 퍼져 있어서 SVM 분류기가 더 잘 일반화할 가능성이 높은 것으로 보입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDtraaS6YIpr"
      },
      "source": [
        "이 결과를 더욱 개선하려면 다음과 같이 할 수 있습니다:\n",
        "* 교차 검증 및 그리드 검색을 사용하여 더 많은 모델을 비교하고 하이퍼파라미터를 조정하세요.\n",
        "* 더 많은 특성 공학을 수행하세요. 예를 들면 다음과 같습니다:\n",
        "  * 숫자 특성을 범주 특성으로 변환해 보세요. 예를 들어, 연령대별로 생존율이 매우 다르므로(아래 참조) 연령 버킷 카테고리를 만들어 연령 대신 사용하는 것이 도움이 될 수 있습니다. 마찬가지로, 혼자 여행하는 사람들의 생존율이 30%에 불과했기 때문에 혼자 여행하는 사람들을 위한 특별 카테고리를 만드는 것이 유용할 수 있습니다(아래 참조).\n",
        "  * **SibSp**와 **Parch**를 합쳐 보세요.\n",
        "  * **Survived** 속성과 잘 연관되는 이름 부분을 찾아보세요.\n",
        "  * **Cabin** 열을 사용하세요. 예를 들어 첫 글자를 가져와 범주형 속성으로 처리합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "BR2R3h9rYIpr",
        "outputId": "0b181829-e6a2-43b3-9349-1abe14b4db1e"
      },
      "outputs": [],
      "source": [
        "train_data[\"AgeBucket\"] = train_data[\"Age\"] // 15 * 15\n",
        "train_data[[\"AgeBucket\", \"Survived\"]].groupby(['AgeBucket']).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "hI3-qB1FYIpr",
        "outputId": "9c8b0e62-ca33-4c5f-8b65-36ecb9ba0d83"
      },
      "outputs": [],
      "source": [
        "train_data[\"RelativesOnboard\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\n",
        "train_data[[\"RelativesOnboard\", \"Survived\"]].groupby(\n",
        "    ['RelativesOnboard']).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBZDFzH1YIpr"
      },
      "source": [
        "## 4. 스팸 필터"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaiDnHz9YIpr"
      },
      "source": [
        "문제: _스팸 분류기를 만들어보세요(아주 도전적인 과제입니다)._\n",
        "\n",
        "* _[아파치 스팸어새신(Apache SpamAssassin) 공공 데이터셋](https://homl.info/spamassassin)에서 스팸(spam)과 햄(ham)(스팸이 아닌 메일) 샘플을 내려받습니다._\n",
        "* _데이터셋의 압축을 풀고 데이터 형식을 살펴봅니다._\n",
        "* _데이터셋을 훈련 세트와 테스트 세트로 나눕니다._\n",
        "* _각 이메일을 특성 벡터로 변환하는 데이터 준비 파이프라인을 만듭니다. 이 준비 파이프라인은 하나의 이메일을 가능한 단어의 존재 여부를 나타내는 (희소) 벡터로 바꿔야 합니다. 예를 들어 모든 이메일이 네 개의 단어 ‘Hello’, ‘how’, ‘are’, ‘you’만 포함한다면 ‘Hello you Hello Hello you’란 이메일은 벡터 [1, 0, 0, 1]([‘Hello’ 있음, ‘how’ 없음, ‘are’ 없음, ‘you’ 있음]을 의미)로 변환되거나, 단어의 출현 횟수에 관심이 있다면 [3, 0, 0, 2]로 변환되어야 합니다._\n",
        "\n",
        "\n",
        "_준비 파이프라인에 이메일 헤더 제거, 소문자 변환, 구두점 제거, 모든 URLs 주소를 ‘URL’로 대체, 모든 숫자를 ‘NUMBER’로 대체, 어간stem 추출20(즉, 단어의 끝을 떼어냅니다. 이런 작업을 할 수 있는 파이썬 라이브러리가 있습니다) 등을 수행할지 여부를 제어하기 위해 하이퍼파라미터를 추가합니다._\n",
        "\n",
        "_마지막으로 여러 분류기를 시도해보고 재현율과 정밀도가 모두 높은 스팸 분류기를 만들 수 있는지 확인해보세요._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "n32xKynzYIps"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "\n",
        "def fetch_spam_data():\n",
        "    spam_root = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
        "    ham_url = spam_root + \"20030228_easy_ham.tar.bz2\"\n",
        "    spam_url = spam_root + \"20030228_spam.tar.bz2\"\n",
        "\n",
        "    spam_path = Path() / \"datasets\" / \"spam\"\n",
        "    spam_path.mkdir(parents=True, exist_ok=True)\n",
        "    for dir_name, tar_name, url in ((\"easy_ham\", \"ham\", ham_url),\n",
        "                                    (\"spam\", \"spam\", spam_url)):\n",
        "        if not (spam_path / dir_name).is_dir():\n",
        "            path = (spam_path / tar_name).with_suffix(\".tar.bz2\")\n",
        "            print(\"Downloading\", path)\n",
        "            urllib.request.urlretrieve(url, path)\n",
        "            tar_bz2_file = tarfile.open(path)\n",
        "            tar_bz2_file.extractall(path=spam_path)\n",
        "            tar_bz2_file.close()\n",
        "    return [spam_path / dir_name for dir_name in (\"easy_ham\", \"spam\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmNgFRP6YIps",
        "outputId": "149a3f39-b2cf-40ad-b143-86a5e3adfa2a"
      },
      "outputs": [],
      "source": [
        "ham_dir, spam_dir = fetch_spam_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMLORF3HYIps"
      },
      "source": [
        "다음, 모든 이메일을 읽어 들입니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "0d9x0vkMYIps"
      },
      "outputs": [],
      "source": [
        "ham_filenames = [f for f in sorted(ham_dir.iterdir()) if len(f.name) > 20]\n",
        "spam_filenames = [f for f in sorted(spam_dir.iterdir()) if len(f.name) > 20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7nt9Gg0YIps",
        "outputId": "f51ea02f-62a9-45c9-e89a-64a701b4f7ab"
      },
      "outputs": [],
      "source": [
        "len(ham_filenames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lh1zRXR-YIps",
        "outputId": "75c07dbf-2be8-412a-b5a6-a57c70ae1b8e"
      },
      "outputs": [],
      "source": [
        "len(spam_filenames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPJYgZbUYIpu"
      },
      "source": [
        "파이썬의 `email` 모듈을 사용해 이메일을 파싱합니다(헤더, 인코딩 등을 처리합니다):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "XRshMQYJYIpu"
      },
      "outputs": [],
      "source": [
        "import email\n",
        "import email.policy\n",
        "\n",
        "def load_email(filepath):\n",
        "    with open(filepath, \"rb\") as f:\n",
        "        return email.parser.BytesParser(policy=email.policy.default).parse(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "v2gUQi4bYIpv"
      },
      "outputs": [],
      "source": [
        "ham_emails = [load_email(filepath) for filepath in ham_filenames]\n",
        "spam_emails = [load_email(filepath) for filepath in spam_filenames]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyPzZ_rkYIpy"
      },
      "source": [
        "데이터가 어떻게 구성되어 있는지 감을 잡기 위해 햄 메일과 스팸 메일을 하나씩 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2ScvYdMYIpy",
        "outputId": "87e78206-5294-4e17-dfbf-edeb050d44b6"
      },
      "outputs": [],
      "source": [
        "print(ham_emails[1].get_content().strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIgv4KU8YIpy",
        "outputId": "0a9f8dee-1e12-43ba-af2b-3e64e7407e2f"
      },
      "outputs": [],
      "source": [
        "print(spam_emails[6].get_content().strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXoxaseSYIpz"
      },
      "source": [
        "어떤 이메일은 이미지나 첨부 파일을 가진 멀티파트(multipart)입니다(메일에 포함되어 있을수 있습니다). 어떤 파일들이 있는지 살펴 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "F_TYPeqaYIpz"
      },
      "outputs": [],
      "source": [
        "def get_email_structure(email):\n",
        "    if isinstance(email, str):\n",
        "        return email\n",
        "    payload = email.get_payload()\n",
        "    if isinstance(payload, list):\n",
        "        multipart = \", \".join([get_email_structure(sub_email)\n",
        "                               for sub_email in payload])\n",
        "        return f\"multipart({multipart})\"\n",
        "    else:\n",
        "        return email.get_content_type()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "JSumLcwgYIpz"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def structures_counter(emails):\n",
        "    structures = Counter()\n",
        "    for email in emails:\n",
        "        structure = get_email_structure(email)\n",
        "        structures[structure] += 1\n",
        "    return structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX_xuzFaYIpz",
        "outputId": "080c426f-cf57-4588-bc08-b70375481c23"
      },
      "outputs": [],
      "source": [
        "structures_counter(ham_emails).most_common()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nN2IcTVYIpz",
        "outputId": "448f5634-6764-4f47-8e40-0f911adac4b3"
      },
      "outputs": [],
      "source": [
        "structures_counter(spam_emails).most_common()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0GGji1tYIpz"
      },
      "source": [
        "햄 메일은 평범한 텍스트가 많고 스팸은 HTML일 경우가 많습니다. 적은 수의 햄 이메일이 PGP로 서명되어 있지만 스팸 메일에는 없습니다. 요약하면 이메일 구조는 유용한 정보입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMY6zElsYIpz"
      },
      "source": [
        "이제 이메일 헤더를 살펴보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKz2NxljYIpz",
        "outputId": "b019fee1-0485-404f-8a47-5219928fce19"
      },
      "outputs": [],
      "source": [
        "for header, value in spam_emails[0].items():\n",
        "    print(header, \":\", value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khGzYb8oYIpz"
      },
      "source": [
        "보낸사람의 이메일 주소와 같이 헤더에는 유용한 정보가 많이 있지만 여기서는 `Subject` 헤더만 다뤄 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "osWHMH9xYIp0",
        "outputId": "79a3f300-1959-471f-980e-d1b005914d62"
      },
      "outputs": [],
      "source": [
        "spam_emails[0][\"Subject\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv_1qxhQYIp0"
      },
      "source": [
        "좋습니다. 데이터에를 더 살펴보기 전에 훈련 세트와 테스트 세트로 나누도록 하겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "AmwSgxApYIp0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = np.array(ham_emails + spam_emails, dtype=object)\n",
        "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilPzqFM_YIp0"
      },
      "source": [
        "이제 전처리 함수를 작성하겠습니다. 먼저 HTML을 일반 텍스트로 변환하는 함수가 필요합니다. 이 작업에는 당연히 [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) 라이브러리를 사용하는게 좋지만 의존성을 줄이기 위해서 정규식을 사용하여 대강 만들어 보겠습니다([un̨ho͞ly radiańcé destro҉ying all enli̍̈́̂̈́ghtenment](https://stackoverflow.com/a/1732454/38626)의 위험에도 불구하고). 다음 함수는 `<head>` 섹션을 삭제하고 모든 `<a>` 태그를 HYPERLINK 문자로 바꿉니다. 그런 다음 모든 HTML 태그를 제거하고 텍스트만 남깁니다. 보기 편하게 여러개의 개행 문자를 하나로 만들고 (`&gt;`나 `&nbsp;` 같은) html 엔티티를 복원합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "3CRd_S7YYIp0"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from html import unescape\n",
        "\n",
        "def html_to_plain_text(html):\n",
        "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
        "    text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
        "    text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
        "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
        "    return unescape(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37a8m_PrYIp0"
      },
      "source": [
        "잘 작동하는지 확인해 보겠습니다. 다음은 HTML 스팸입니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Sh1rEM5YIp0",
        "outputId": "8d4f9a48-1fb7-4181-ea4d-380d0e925dae"
      },
      "outputs": [],
      "source": [
        "html_spam_emails = [email for email in X_train[y_train==1]\n",
        "                    if get_email_structure(email) == \"text/html\"]\n",
        "sample_html_spam = html_spam_emails[7]\n",
        "print(sample_html_spam.get_content().strip()[:1000], \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDMKh-wwYIp0"
      },
      "source": [
        "변환된 텍스트입니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EliXiGlJYIp0",
        "outputId": "b90d24eb-983e-493f-de35-5450e196c599"
      },
      "outputs": [],
      "source": [
        "print(html_to_plain_text(sample_html_spam.get_content())[:1000], \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx6DY_YOYIp1"
      },
      "source": [
        "아주 좋습니다! 이제 포맷에 상관없이 이메일을 입력으로 받아서 일반 텍스트를 출력하는 함수를 만들겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "yUOOLobTYIp1"
      },
      "outputs": [],
      "source": [
        "def email_to_text(email):\n",
        "    html = None\n",
        "    for part in email.walk():\n",
        "        ctype = part.get_content_type()\n",
        "        if not ctype in (\"text/plain\", \"text/html\"):\n",
        "            continue\n",
        "        try:\n",
        "            content = part.get_content()\n",
        "        except: # in case of encoding issues\n",
        "            content = str(part.get_payload())\n",
        "        if ctype == \"text/plain\":\n",
        "            return content\n",
        "        else:\n",
        "            html = content\n",
        "    if html:\n",
        "        return html_to_plain_text(html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQTzEmPZYIp1",
        "outputId": "08a17700-2fd8-4cc0-8f2c-746c8748d45b"
      },
      "outputs": [],
      "source": [
        "print(email_to_text(sample_html_spam)[:100], \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgdIci-oYIp1"
      },
      "source": [
        "자연어 처리 툴킷([NLTK](http://www.nltk.org/))을 사용해 어간 추출을 해보죠:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-KfLTVSYIp1",
        "outputId": "4b171e6d-bcca-482b-815c-47e77243ee1a"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "stemmer = nltk.PorterStemmer()\n",
        "for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\",\n",
        "             \"Compulsive\"):\n",
        "    print(word, \"=>\", stemmer.stem(word))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PQ0c9qzYIp1"
      },
      "source": [
        "인터넷 주소는 \"URL\" 문자로 바꾸겠습니다. [정규식](https://mathiasbynens.be/demo/url-regex)을 하드 코딩할 수도 있지만 [urlextract](https://github.com/lipoja/URLExtract) 라이브러리를 사용하겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "-p3jhyy4YIp1"
      },
      "outputs": [],
      "source": [
        "# 코랩이나 캐글을 사용하나요?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
        "\n",
        "# 코랩이나 캐글에서 이 노트북을 실행하려면 먼저 pip install urlextract을 실행합니다\n",
        "if IS_COLAB or IS_KAGGLE:\n",
        "    %pip install -q -U urlextract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_rqvF47YIp2"
      },
      "source": [
        "**노트:** 주피터 노트북에서는 항상 `!pip` 대신 `%pip`를 사용해야 합니다. `!pip`는 다른 환경에 라이브러리를 설치할 수 있기 때문입니다. 반면 `%pip`는 현재 실행 중인 환경에 설치됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA6TtPWJYIp2",
        "outputId": "d77904f1-d6ff-4138-d2d8-672500c02a19"
      },
      "outputs": [],
      "source": [
        "import urlextract # 루트 도메인 이름을 다운로드하기 위해 인터넷 연결이 필요할지 모릅니다\n",
        "\n",
        "url_extractor = urlextract.URLExtract()\n",
        "some_text = \"Will it detect github.com and https://youtu.be/7Pq-S557XQU?t=3m32s\"\n",
        "print(url_extractor.find_urls(some_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzIAyZKcYIp2"
      },
      "source": [
        "이들을 모두 하나의 변환기로 연결하여 이메일을 단어 카운트로 바꿀 것입니다. 파이썬의 `split()` 메서드를 사용하면 구둣점과 단어 경계를 기준으로 문장을 단어로 바꿉니다. 이 방법이 많은 언어에 통하지만 전부는 아닙니다. 예를 들어 중국어와 일본어는 일반적으로 단어 사이에 공백을 두지 않습니다. 베트남어는 음절 사이에 공백을 두기도 합니다. 여기서는 데이터셋이 (거의) 영어로 되어 있기 때문에 문제없습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "1wx8HVkmYIp2"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, strip_headers=True, lower_case=True,\n",
        "                 remove_punctuation=True, replace_urls=True,\n",
        "                 replace_numbers=True, stemming=True):\n",
        "        self.strip_headers = strip_headers\n",
        "        self.lower_case = lower_case\n",
        "        self.remove_punctuation = remove_punctuation\n",
        "        self.replace_urls = replace_urls\n",
        "        self.replace_numbers = replace_numbers\n",
        "        self.stemming = stemming\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        X_transformed = []\n",
        "        for email in X:\n",
        "            text = email_to_text(email) or \"\"\n",
        "            if self.lower_case:\n",
        "                text = text.lower()\n",
        "            if self.replace_urls and url_extractor is not None:\n",
        "                urls = list(set(url_extractor.find_urls(text)))\n",
        "                urls.sort(key=lambda url: len(url), reverse=True)\n",
        "                for url in urls:\n",
        "                    text = text.replace(url, \" URL \")\n",
        "            if self.replace_numbers:\n",
        "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
        "            if self.remove_punctuation:\n",
        "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
        "            word_counts = Counter(text.split())\n",
        "            if self.stemming and stemmer is not None:\n",
        "                stemmed_word_counts = Counter()\n",
        "                for word, count in word_counts.items():\n",
        "                    stemmed_word = stemmer.stem(word)\n",
        "                    stemmed_word_counts[stemmed_word] += count\n",
        "                word_counts = stemmed_word_counts\n",
        "            X_transformed.append(word_counts)\n",
        "        return np.array(X_transformed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfgVwxb5YIp2"
      },
      "source": [
        "이 변환기를 몇 개의 이메일에 적용해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3PzvOIpYIp2",
        "outputId": "883796e9-5805-428d-bf4a-76b8504c636d"
      },
      "outputs": [],
      "source": [
        "X_few = X_train[:3]\n",
        "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)\n",
        "X_few_wordcounts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCeWf7M4YIp2"
      },
      "source": [
        "제대로 작동하는 것 같네요!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Erq03MvNYIp2"
      },
      "source": [
        "이제 단어 카운트를 벡터로 변환해야 합니다. 이를 위해서 또 다른 변환기를 만들겠습니다. 이 변환기는 (자주 나타나는 단어 순으로 정렬된) 어휘 목록을 구축하는 `fit()` 메서드와 어휘 목록을 사용해 단어를 벡터로 바꾸는 `transform()` 메서드를 가집니다. 출력은 희소 행렬이 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "aSwgg4p5YIp2"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, vocabulary_size=1000):\n",
        "        self.vocabulary_size = vocabulary_size\n",
        "    def fit(self, X, y=None):\n",
        "        total_count = Counter()\n",
        "        for word_count in X:\n",
        "            for word, count in word_count.items():\n",
        "                total_count[word] += min(count, 10)\n",
        "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
        "        self.vocabulary_ = {word: index + 1\n",
        "                            for index, (word, count) in enumerate(most_common)}\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        rows = []\n",
        "        cols = []\n",
        "        data = []\n",
        "        for row, word_count in enumerate(X):\n",
        "            for word, count in word_count.items():\n",
        "                rows.append(row)\n",
        "                cols.append(self.vocabulary_.get(word, 0))\n",
        "                data.append(count)\n",
        "        return csr_matrix((data, (rows, cols)),\n",
        "                          shape=(len(X), self.vocabulary_size + 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq6Hf62uYIp3",
        "outputId": "0dd8fefa-5141-42e1-9bfa-431795ae71e0"
      },
      "outputs": [],
      "source": [
        "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
        "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
        "X_few_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZI6kJWkYIp3",
        "outputId": "694eb920-f63a-415b-8ae2-ffb94b2d89cd"
      },
      "outputs": [],
      "source": [
        "X_few_vectors.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2o4_tZBYIp3"
      },
      "source": [
        "이 행렬은 무엇을 의미하나요? 세 번째 행의 첫 번째 열의 65는 세 번째 이메일이 어휘 목록에 없는 단어를 65개 가지고 있다는 뜻입니다. 그 다음의 0은 어휘 목록에 있는 첫 번째 단어가 한 번도 등장하지 않는다는 뜻이고 그 다음의 1은 한 번 나타난다는 뜻입니다. 이 단어들이 무엇인지 확인하려면 어휘 목록을 보면 됩니다. 첫 번째 단어는 \"the\"이고 두 번째 단어는 \"of\"입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFSYRoLsYIp3",
        "outputId": "64b0ff88-5423-4a06-8aee-c0a28fcb1e6a"
      },
      "outputs": [],
      "source": [
        "vocab_transformer.vocabulary_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKiGJhCEYIp3"
      },
      "source": [
        "이제 스팸 분류기를 훈련시킬 준비를 마쳤습니다! 전체 데이터셋을 변환시켜보죠:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "0I-3niy9YIp3"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "preprocess_pipeline = Pipeline([\n",
        "    (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
        "    (\"wordcount_to_vector\", WordCounterToVectorTransformer()),\n",
        "])\n",
        "\n",
        "X_train_transformed = preprocess_pipeline.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK2M7H3wYIp3",
        "outputId": "63f86b65-fad2-4a09-b160-f3f26196fdc1"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "log_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "score = cross_val_score(log_clf, X_train_transformed, y_train, cv=3)\n",
        "score.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rpw1eYE4YIp4"
      },
      "source": [
        "98.5%가 넘네요. 첫 번째 시도치고 나쁘지 않습니다! :) 그러나 이 데이터셋은 비교적 쉬운 문제입니다. 더 어려운 데이터셋에 적용해 보면 결과가 그리 높지 않을 것입니다. 여러개의 모델을 시도해 보고 제일 좋은 것을 골라 교차 검증으로 세밀하게 튜닝해 보세요.\n",
        "\n",
        "하지만 전체 내용을 파악했으므로 여기서 멈추겠습니다. 테스트 세트에서 정밀도/재현율을 출력해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzUn5ocYYIp4",
        "outputId": "de6d72e8-e08e-4088-89bd-1129b3e21055"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
        "\n",
        "log_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_clf.fit(X_train_transformed, y_train)\n",
        "\n",
        "y_pred = log_clf.predict(X_test_transformed)\n",
        "\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.2%}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.2%}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
